{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5dcadf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Public\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c68771",
   "metadata": {},
   "source": [
    "## neural network regression with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca72c2",
   "metadata": {},
   "source": [
    " #### introduction to regression with neural networks in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9a32f",
   "metadata": {},
   "source": [
    "## creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13cc4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34fce4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features \n",
    "\n",
    "x = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef2691e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels \n",
    "\n",
    "y =np.array([3.0,6.0,9.0,12.0,15.0,18.,21.0,24.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9e85889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c6a13441f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4876049e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == x +10  # relationship between x and y or relationship between dependent and independent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de726d46",
   "metadata": {},
   "source": [
    "## input and output shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44be8640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom ', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a demo tensor for our housing price prediction problem\n",
    "\n",
    "house_info = tf.constant(['bedroom ','bathroom' , 'garage'])\n",
    "\n",
    "house_price = tf.constant([939700])\n",
    "\n",
    "house_info , house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49f9ca6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x.shape\n",
    "\n",
    "output_shape = y.shape\n",
    "\n",
    "input_shape , output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11515827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] , y[0]\n",
    "\n",
    "# we are using one x value to predict the one y value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785dbe1",
   "metadata": {},
   "source": [
    "so here also we are using one house  as an input to predict the price of one house "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6efcd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd3a36aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0679120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn out numpy arrays into tensors \n",
    "\n",
    "x = tf.constant(x)\n",
    "y = tf.constant(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f413c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
       " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2538d8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape # when there is no dimension we will get a scaler value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "008f6f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b9b70f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c6a12de1c0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef7a49",
   "metadata": {},
   "source": [
    "## steps in modeling with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379a6f7",
   "metadata": {},
   "source": [
    " 1. create a model  -- define the input and output layers as well as hidden layers of a deep learning model\n",
    "\n",
    " 2. compiling a model -- define  the loss function (in other words , the function which tells our model how wrong it is ) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of a model)\n",
    " \n",
    " 3. fitting a model -- letting the model try to find patterns between  x and y (features and labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12ce35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create a model using the sequential API\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "]\n",
    "\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb03a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,optimizer = tf.keras.optimizers.SGD(),metrics =['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71bd12c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_3' (type Sequential).\n    \n    Input 0 of layer \"dense_4\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_3' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13772/1328393846.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Users\\Public\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_3' (type Sequential).\n    \n    Input 0 of layer \"dense_4\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential_3' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit(x,y,epochs=5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d766b",
   "metadata": {},
   "source": [
    "here the error is because of less dimensions of the tensor and the we have created the tensors through arrays so the dtype is float64 and we need to convert it into float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ff800a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.cast(x,dtype=tf.float32)\n",
    "y = tf.cast(y,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb46dd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c99868a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.expand_dims(x,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9cf23d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 12.0145 - mae: 12.0145\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.8235 - mae: 11.8235\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.6242 - mae: 11.6242\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.4155 - mae: 11.4155\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.1965 - mae: 11.1965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c6a13d33d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can compile the model\n",
    "# fit the model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create a model using the sequential API\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "]\n",
    "\n",
    "\n",
    ")\n",
    "model.compile(loss=tf.keras.losses.mae,optimizer = tf.keras.optimizers.SGD(),metrics =['mae'])\n",
    "\n",
    "model.fit(x,y,epochs=5)  # we need to make loss == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19be8f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       " array([[-7.],\n",
       "        [-4.],\n",
       "        [-1.],\n",
       "        [ 2.],\n",
       "        [ 5.],\n",
       "        [ 8.],\n",
       "        [11.],\n",
       "        [14.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out x and y\n",
    "\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84a407cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 261ms/step\n"
     ]
    }
   ],
   "source": [
    "# try and make a prediction using our model\n",
    "\n",
    "y_pred=model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f91a797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.064958]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e28c333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.064957]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 15\n",
    "\n",
    "# this model is not predicting well so we need to improve the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5cda9f",
   "metadata": {},
   "source": [
    "## improving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0c44e",
   "metadata": {},
   "source": [
    "we can improve the model by altering the steps we took to create a model\n",
    "\n",
    "1.**creating a model ** --- here we might add more layers , increase the number of hidden units , within each of the hidden layers change the activation function\n",
    "\n",
    "2. ** compiling a model ** --- here we might change the optimization funtion and **learning rate ** of the optmization funtion \n",
    "\n",
    "3. ** fitting a model ** --- here we might fit a model for more **epochs ** (leave it training for longer ) or on more data(give the model more examples to learn from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed39ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 9.3474 - mae: 9.3474\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.2149 - mae: 9.2149\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.0824 - mae: 9.0824\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.9499 - mae: 8.9499\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.8174 - mae: 8.8174\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.6849 - mae: 8.6849\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.5524 - mae: 8.5524\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.4199 - mae: 8.4199\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.2874 - mae: 8.2874\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1549 - mae: 8.1549\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.0224 - mae: 8.0224\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.8899 - mae: 7.8899\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7574 - mae: 7.7574\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.6249 - mae: 7.6249\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.4924 - mae: 7.4924\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3875 - mae: 7.3875\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.3819 - mae: 7.3819\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.3763 - mae: 7.3763\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.3706 - mae: 7.3706\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.3650 - mae: 7.3650\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3594 - mae: 7.3594\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.3538 - mae: 7.3538\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.3425 - mae: 7.3425\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3369 - mae: 7.3369\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.3313 - mae: 7.3313\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.3256 - mae: 7.3256\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.3200 - mae: 7.3200\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.3144 - mae: 7.3144\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.3088 - mae: 7.3088\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3031 - mae: 7.3031\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2975 - mae: 7.2975\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2919 - mae: 7.2919\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2862 - mae: 7.2862\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2806 - mae: 7.2806\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.2412 - mae: 7.2412\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.1063 - mae: 7.1063\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8869 - mae: 6.8869\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8813 - mae: 6.8813\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8756 - mae: 6.8756\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8700 - mae: 6.8700\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8644 - mae: 6.8644\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8588 - mae: 6.8588\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8531 - mae: 6.8531\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8475 - mae: 6.8475\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8419 - mae: 6.8419\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8363 - mae: 6.8363\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8306 - mae: 6.8306\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8250 - mae: 6.8250\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8194 - mae: 6.8194\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8138 - mae: 6.8138\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8081 - mae: 6.8081\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8025 - mae: 6.8025\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7969 - mae: 6.7969\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7913 - mae: 6.7913\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7856 - mae: 6.7856\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.7800 - mae: 6.7800\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.7744 - mae: 6.7744\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7688 - mae: 6.7688\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7631 - mae: 6.7631\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.7575 - mae: 6.7575\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7519 - mae: 6.7519\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7463 - mae: 6.7463\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7406 - mae: 6.7406\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7350 - mae: 6.7350\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7294 - mae: 6.7294\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.7238 - mae: 6.7238\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.7181 - mae: 6.7181\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7125 - mae: 6.7125\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7069 - mae: 6.7069\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7013 - mae: 6.7013\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6956 - mae: 6.6956\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6900 - mae: 6.6900\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6844 - mae: 6.6844\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6788 - mae: 6.6788\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6731 - mae: 6.6731\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6675 - mae: 6.6675\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6619 - mae: 6.6619\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6562 - mae: 6.6562\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.6506 - mae: 6.6506\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6450 - mae: 6.6450\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6394 - mae: 6.6394\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.6337 - mae: 6.6337\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6281 - mae: 6.6281\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6225 - mae: 6.6225\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6169 - mae: 6.6169\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6112 - mae: 6.6112\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6056 - mae: 6.6056\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6000 - mae: 6.6000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.5944 - mae: 6.5944\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5887 - mae: 6.5887\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.5831 - mae: 6.5831\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.5775 - mae: 6.5775\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.5719 - mae: 6.5719\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.5662 - mae: 6.5662\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.5606 - mae: 6.5606\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.5550 - mae: 6.5550\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5494 - mae: 6.5494\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.5437 - mae: 6.5437\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5381 - mae: 6.5381\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.5325 - mae: 6.5325\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.5269 - mae: 6.5269\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.5212 - mae: 6.5212\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5156 - mae: 6.5156\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.5100 - mae: 6.5100\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.5044 - mae: 6.5044\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4987 - mae: 6.4987\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4931 - mae: 6.4931\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.4875 - mae: 6.4875\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.4819 - mae: 6.4819\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.4762 - mae: 6.4762\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4706 - mae: 6.4706\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.4650 - mae: 6.4650\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4594 - mae: 6.4594\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4537 - mae: 6.4537\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.4481 - mae: 6.4481\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4425 - mae: 6.4425\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.4369 - mae: 6.4369\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4312 - mae: 6.4312\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4256 - mae: 6.4256\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4200 - mae: 6.4200\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.4144 - mae: 6.4144\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4087 - mae: 6.4087\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4031 - mae: 6.4031\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3975 - mae: 6.3975\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3919 - mae: 6.3919\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3862 - mae: 6.3862\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3806 - mae: 6.3806\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3750 - mae: 6.3750\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3694 - mae: 6.3694\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3637 - mae: 6.3637\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3581 - mae: 6.3581\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3525 - mae: 6.3525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c69c13cdc0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets rebuilt our model\n",
    "\n",
    "# create the model\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "    \n",
    "]\n",
    ")\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae , optimizer = tf.keras.optimizers.SGD() , metrics = ['mae'])\n",
    "\n",
    "\n",
    "model.fit(x , y ,epochs =200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9fa0183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 249ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30.632336]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])  # here our prediction is improved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45f59666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try another model \n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(1)\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c021afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.mae, optimizer = tf.keras.optimizers.Adam() , metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18c5f0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18.1113 - mae: 18.1113\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.1053 - mae: 18.1053\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.0993 - mae: 18.0993\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.0933 - mae: 18.0933\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.0873 - mae: 18.0873\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 18.0813 - mae: 18.0813\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.0753 - mae: 18.0753\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.0693 - mae: 18.0693\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.0633 - mae: 18.0633\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 18.0573 - mae: 18.0573\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.0513 - mae: 18.0513\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.0453 - mae: 18.0453\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.0393 - mae: 18.0393\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.0333 - mae: 18.0333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.0273 - mae: 18.0273\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 18.0213 - mae: 18.0213\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.0153 - mae: 18.0153\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.0093 - mae: 18.0093\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.0033 - mae: 18.0033\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.9973 - mae: 17.9973\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9913 - mae: 17.9913\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.9853 - mae: 17.9853\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.9793 - mae: 17.9793\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.9733 - mae: 17.9733\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9673 - mae: 17.9673\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.9613 - mae: 17.9613\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.9553 - mae: 17.9553\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.9493 - mae: 17.9493\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 17.9433 - mae: 17.9433\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.9373 - mae: 17.9373\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.9313 - mae: 17.9313\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.9253 - mae: 17.9253\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 17.9193 - mae: 17.9193\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 17.9133 - mae: 17.9133\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.9073 - mae: 17.9073\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 17.9013 - mae: 17.9013\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 17.8953 - mae: 17.8953\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.8893 - mae: 17.8893\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.8833 - mae: 17.8833\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8773 - mae: 17.8773\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.8713 - mae: 17.8713\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.8653 - mae: 17.8653\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.8593 - mae: 17.8593\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.8533 - mae: 17.8533\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.8473 - mae: 17.8473\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.8413 - mae: 17.8413\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.8353 - mae: 17.8353\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.8293 - mae: 17.8293\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.8233 - mae: 17.8233\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8173 - mae: 17.8173\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.8113 - mae: 17.8113\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.8053 - mae: 17.8053\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.7993 - mae: 17.7993\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.7933 - mae: 17.7933\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.7873 - mae: 17.7873\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.7813 - mae: 17.7813\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 17.7753 - mae: 17.7753\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.7693 - mae: 17.7693\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.7633 - mae: 17.7633\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.7573 - mae: 17.7573\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.7513 - mae: 17.7513\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.7453 - mae: 17.7453\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.7393 - mae: 17.7393\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.7333 - mae: 17.7333\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.7273 - mae: 17.7273\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.7213 - mae: 17.7213\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 17.7153 - mae: 17.7153\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.7093 - mae: 17.7093\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 17.7033 - mae: 17.7033\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.6973 - mae: 17.6973\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.6913 - mae: 17.6913\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 17.6853 - mae: 17.6853\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 17.6793 - mae: 17.6793\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 17.6733 - mae: 17.6733\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.6673 - mae: 17.6673\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.6613 - mae: 17.6613\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.6553 - mae: 17.6553\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.6493 - mae: 17.6493\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.6433 - mae: 17.6433\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.6373 - mae: 17.6373\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.6313 - mae: 17.6313\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.6253 - mae: 17.6253\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.6193 - mae: 17.6193\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.6133 - mae: 17.6133\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.6073 - mae: 17.6073\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.6013 - mae: 17.6013\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.5953 - mae: 17.5953\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.5893 - mae: 17.5893\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.5833 - mae: 17.5833\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.5773 - mae: 17.5773\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.5713 - mae: 17.5713\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17.5653 - mae: 17.5653\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.5593 - mae: 17.5593\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.5533 - mae: 17.5533\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.5473 - mae: 17.5473\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.5413 - mae: 17.5413\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.5353 - mae: 17.5353\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.5293 - mae: 17.5293\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.5233 - mae: 17.5233\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.5173 - mae: 17.5173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c6a02ea130>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x , y , epochs =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8cd1c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 243ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-15.560392]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5be1f",
   "metadata": {},
   "source": [
    "### lets try by adding the hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb891c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f34fc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.SGD(),metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1bbd7f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 13.5211 - mae: 13.5211\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.0038 - mae: 13.0038\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.4905 - mae: 12.4905\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.9708 - mae: 11.9708\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.4399 - mae: 11.4399\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 10.9057 - mae: 10.9057\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.3613 - mae: 10.3613\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.8043 - mae: 9.8043\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.2242 - mae: 9.2242\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.6103 - mae: 8.6103\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.9678 - mae: 7.9678\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.2806 - mae: 7.2806\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.5408 - mae: 6.5408\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.8084 - mae: 5.8084\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.0142 - mae: 5.0142\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1776 - mae: 4.1776\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.0874 - mae: 4.0874\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9948 - mae: 3.9948\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8995 - mae: 3.8995\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9538 - mae: 3.9538\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.8948 - mae: 3.8948\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9534 - mae: 3.9534\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9036 - mae: 3.9036\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.9283 - mae: 3.9283\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9098 - mae: 3.9098\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9030 - mae: 3.9030\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9162 - mae: 3.9162\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8775 - mae: 3.8775\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9289 - mae: 3.9289\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.8667 - mae: 3.8667\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9308 - mae: 3.9308\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.8731 - mae: 3.8731\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9055 - mae: 3.9055\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8795 - mae: 3.8795\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8799 - mae: 3.8799\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8860 - mae: 3.8860\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8608 - mae: 3.8608\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9017 - mae: 3.9017\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8371 - mae: 3.8371\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9070 - mae: 3.9070\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8437 - mae: 3.8437\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8814 - mae: 3.8814\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.8503 - mae: 3.8503\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8556 - mae: 3.8556\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8633 - mae: 3.8633\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8380 - mae: 3.8380\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8729 - mae: 3.8729\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8118 - mae: 3.8118\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8798 - mae: 3.8798\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8154 - mae: 3.8154\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8560 - mae: 3.8560\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8222 - mae: 3.8222\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8361 - mae: 3.8361\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8382 - mae: 3.8382\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8121 - mae: 3.8121\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8452 - mae: 3.8452\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7856 - mae: 3.7856\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8524 - mae: 3.8524\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7883 - mae: 3.7883\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8296 - mae: 3.8296\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8004 - mae: 3.8004\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8116 - mae: 3.8116\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8115 - mae: 3.8115\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7850 - mae: 3.7850\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8187 - mae: 3.8187\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7582 - mae: 3.7582\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8261 - mae: 3.8261\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7623 - mae: 3.7623\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8062 - mae: 3.8062\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7785 - mae: 3.7785\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7835 - mae: 3.7835\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7858 - mae: 3.7858\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7565 - mae: 3.7565\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7932 - mae: 3.7932\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7300 - mae: 3.7300\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7995 - mae: 3.7995\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7405 - mae: 3.7405\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7810 - mae: 3.7810\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7537 - mae: 3.7537\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7540 - mae: 3.7540\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7612 - mae: 3.7612\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7268 - mae: 3.7268\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7689 - mae: 3.7689\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7059 - mae: 3.7059\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7717 - mae: 3.7717\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7224 - mae: 3.7224\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7506 - mae: 3.7506\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7300 - mae: 3.7300\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7232 - mae: 3.7232\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7377 - mae: 3.7377\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.6958 - mae: 3.6958\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7456 - mae: 3.7456\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.6837 - mae: 3.6837\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7463 - mae: 3.7463\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6995 - mae: 3.6995\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7188 - mae: 3.7188\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7072 - mae: 3.7072\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6911 - mae: 3.6911\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7152 - mae: 3.7152\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.6634 - mae: 3.6634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c6a0201c10>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37874f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       " array([[-7.],\n",
       "        [-4.],\n",
       "        [-1.],\n",
       "        [ 2.],\n",
       "        [ 5.],\n",
       "        [ 8.],\n",
       "        [11.],\n",
       "        [14.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x , y\n",
    "\n",
    "# if we add 17.0 then model need to predict 27 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9470472c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.899536]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0]) # here the prediction is not accurate \n",
    "\n",
    "# the model is overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a532351d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.5724 - mae: 12.5724\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 12.5025 - mae: 12.5025\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 12.4325 - mae: 12.4325\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 12.3624 - mae: 12.3624\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.2923 - mae: 12.2923\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.2221 - mae: 12.2221\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.1518 - mae: 12.1518\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.0814 - mae: 12.0814\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.0110 - mae: 12.0110\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.9404 - mae: 11.9404\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.8698 - mae: 11.8698\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.7991 - mae: 11.7991\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.7282 - mae: 11.7282\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.6573 - mae: 11.6573\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.5863 - mae: 11.5863\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.5151 - mae: 11.5151\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.4438 - mae: 11.4438\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.3724 - mae: 11.3724\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.3009 - mae: 11.3009\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.2292 - mae: 11.2292\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.1574 - mae: 11.1574\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.0854 - mae: 11.0854\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.0133 - mae: 11.0133\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.9409 - mae: 10.9409\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.8685 - mae: 10.8685\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.7958 - mae: 10.7958\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.7229 - mae: 10.7229\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.6498 - mae: 10.6498\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.5765 - mae: 10.5765\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.5029 - mae: 10.5029\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.4291 - mae: 10.4291\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.3551 - mae: 10.3551\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.2808 - mae: 10.2808\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.2062 - mae: 10.2062\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 10.1313 - mae: 10.1313\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.0561 - mae: 10.0561\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.9807 - mae: 9.9807\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.9049 - mae: 9.9049\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.8288 - mae: 9.8288\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.7523 - mae: 9.7523\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.6755 - mae: 9.6755\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.5983 - mae: 9.5983\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.5208 - mae: 9.5208\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.4429 - mae: 9.4429\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.3646 - mae: 9.3646\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.2859 - mae: 9.2859\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.2068 - mae: 9.2068\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.1273 - mae: 9.1273\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.0473 - mae: 9.0473\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.9669 - mae: 8.9669\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.8861 - mae: 8.8861\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.8048 - mae: 8.8048\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.7231 - mae: 8.7231\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.6409 - mae: 8.6409\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.5582 - mae: 8.5582\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.4750 - mae: 8.4750\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.3913 - mae: 8.3913\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.3071 - mae: 8.3071\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.2224 - mae: 8.2224\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.1372 - mae: 8.1372\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.0514 - mae: 8.0514\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9651 - mae: 7.9651\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.8782 - mae: 7.8782\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7908 - mae: 7.7908\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7028 - mae: 7.7028\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.6143 - mae: 7.6143\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.5251 - mae: 7.5251\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.4354 - mae: 7.4354\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.3451 - mae: 7.3451\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.2541 - mae: 7.2541\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1626 - mae: 7.1626\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0704 - mae: 7.0704\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9777 - mae: 6.9777\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8842 - mae: 6.8842\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8690 - mae: 6.8690\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8580 - mae: 6.8580\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.8473 - mae: 6.8473\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8368 - mae: 6.8368\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8266 - mae: 6.8266\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8165 - mae: 6.8165\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8065 - mae: 6.8065\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7967 - mae: 6.7967\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7870 - mae: 6.7870\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7775 - mae: 6.7775\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7680 - mae: 6.7680\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7789 - mae: 6.7789\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7881 - mae: 6.7881\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.7907 - mae: 6.7907\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7871 - mae: 6.7871\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7781 - mae: 6.7781\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7642 - mae: 6.7642\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7459 - mae: 6.7459\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7236 - mae: 6.7236\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6997 - mae: 6.6997\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6933 - mae: 6.6933\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6867 - mae: 6.6867\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6800 - mae: 6.6800\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.6730 - mae: 6.6730\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.6659 - mae: 6.6659\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.6586 - mae: 6.6586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c6a13ce8e0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the hidden layers \n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(50,activation=None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "]\n",
    "\n",
    ")\n",
    "model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam(),metrics=['mae'])\n",
    "model.fit(x,y,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4c45bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C6A1531F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 309ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31.3208]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0db04cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 219.1458 - mse: 219.1458\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 210.5827 - mse: 210.5827\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 202.9741 - mse: 202.9741\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 195.2779 - mse: 195.2779\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 187.6894 - mse: 187.6894\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 180.8013 - mse: 180.8013\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 174.6218 - mse: 174.6218\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 168.3097 - mse: 168.3097\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 161.7040 - mse: 161.7040\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 154.9988 - mse: 154.9988\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 148.0577 - mse: 148.0577\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 140.9892 - mse: 140.9892\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 134.1035 - mse: 134.1035\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 127.1276 - mse: 127.1276\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 120.0264 - mse: 120.0264\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 112.6504 - mse: 112.6504\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 105.1235 - mse: 105.1235\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 97.4845 - mse: 97.4845\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 89.7941 - mse: 89.7941\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 82.0413 - mse: 82.0413\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 74.2975 - mse: 74.2975\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 66.6929 - mse: 66.6929\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 59.3298 - mse: 59.3298\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 52.3191 - mse: 52.3191\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 45.7786 - mse: 45.7786\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 39.8351 - mse: 39.8351\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 34.5922 - mse: 34.5922\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 30.1265 - mse: 30.1265\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 26.5067 - mse: 26.5067\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 23.7947 - mse: 23.7947\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.0242 - mse: 22.0242\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 21.1928 - mse: 21.1928\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 21.2102 - mse: 21.2102\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21.8909 - mse: 21.8909\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.0234 - mse: 23.0234\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.3511 - mse: 24.3511\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 25.6169 - mse: 25.6169\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 26.6355 - mse: 26.6355\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 27.2187 - mse: 27.2187\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.3428 - mse: 27.3428\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 27.0595 - mse: 27.0595\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 26.4383 - mse: 26.4383\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25.5614 - mse: 25.5614\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 24.5451 - mse: 24.5451\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.5016 - mse: 23.5016\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 22.5191 - mse: 22.5191\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 21.6901 - mse: 21.6901\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 20.9966 - mse: 20.9966\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 20.4844 - mse: 20.4844\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 20.1342 - mse: 20.1342\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.9572 - mse: 19.9572\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.8742 - mse: 19.8742\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.8598 - mse: 19.8598\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 19.8797 - mse: 19.8797\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 19.9044 - mse: 19.9044\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.9091 - mse: 19.9091\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.8825 - mse: 19.8825\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 19.8210 - mse: 19.8210\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.7211 - mse: 19.7211\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.5875 - mse: 19.5875\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 19.4264 - mse: 19.4264\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 19.2519 - mse: 19.2519\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.0744 - mse: 19.0744\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 18.8957 - mse: 18.8957\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.7302 - mse: 18.7302\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.5770 - mse: 18.5770\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.4681 - mse: 18.4681\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.3809 - mse: 18.3809\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.3041 - mse: 18.3041\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.2249 - mse: 18.2249\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 18.1302 - mse: 18.1302\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.0147 - mse: 18.0147\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.8793 - mse: 17.8793\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.7263 - mse: 17.7263\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.5610 - mse: 17.5610\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.3901 - mse: 17.3901\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.2214 - mse: 17.2214\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17.0743 - mse: 17.0743\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.9145 - mse: 16.9145\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 16.7589 - mse: 16.7589\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.5902 - mse: 16.5902\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.4042 - mse: 16.4042\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.2196 - mse: 16.2196\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 16.0290 - mse: 16.0290\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 15.8339 - mse: 15.8339\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 15.6197 - mse: 15.6197\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 15.4146 - mse: 15.4146\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 15.2051 - mse: 15.2051\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 14.9881 - mse: 14.9881\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 14.7690 - mse: 14.7690\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 14.5311 - mse: 14.5311\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 14.2651 - mse: 14.2651\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.9606 - mse: 13.9606\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 13.6465 - mse: 13.6465\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.3975 - mse: 13.3975\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 13.1059 - mse: 13.1059\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.8052 - mse: 12.8052\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.5335 - mse: 12.5335\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 12.2276 - mse: 12.2276\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.9088 - mse: 11.9088\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.5912 - mse: 11.5912\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.2604 - mse: 11.2604\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.9135 - mse: 10.9135\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.5660 - mse: 10.5660\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.1783 - mse: 10.1783\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.7791 - mse: 9.7791\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.4359 - mse: 9.4359\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.0867 - mse: 9.0867\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.6947 - mse: 8.6947\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.2668 - mse: 8.2668\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.9139 - mse: 7.9139\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.5174 - mse: 7.5174\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0873 - mse: 7.0873\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7041 - mse: 6.7041\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.3506 - mse: 6.3506\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.9591 - mse: 5.9591\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.5756 - mse: 5.5756\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2245 - mse: 5.2245\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8989 - mse: 4.8989\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.5688 - mse: 4.5688\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.2207 - mse: 4.2207\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8706 - mse: 3.8706\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.5612 - mse: 3.5612\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2841 - mse: 3.2841\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.0003 - mse: 3.0003\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7505 - mse: 2.7505\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5246 - mse: 2.5246\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2813 - mse: 2.2813\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0408 - mse: 2.0408\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9094 - mse: 1.9094\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7718 - mse: 1.7718\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6142 - mse: 1.6142\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4864 - mse: 1.4864\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3647 - mse: 1.3647\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2408 - mse: 1.2408\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1314 - mse: 1.1314\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0438 - mse: 1.0438\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9855 - mse: 0.9855\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9376 - mse: 0.9376\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8943 - mse: 0.8943\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8554 - mse: 0.8554\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8129 - mse: 0.8129\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7722 - mse: 0.7722\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7274 - mse: 0.7274\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6838 - mse: 0.6838\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6445 - mse: 0.6445\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6072 - mse: 0.6072\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5717 - mse: 0.5717\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5363 - mse: 0.5363\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5011 - mse: 0.5011\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4658 - mse: 0.4658\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4356 - mse: 0.4356\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4071 - mse: 0.4071\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3788 - mse: 0.3788\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3536 - mse: 0.3536\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3301 - mse: 0.3301\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3059 - mse: 0.3059\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2844 - mse: 0.2844\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2648 - mse: 0.2648\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2459 - mse: 0.2459\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2303 - mse: 0.2303\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2154 - mse: 0.2154\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2005 - mse: 0.2005\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1741 - mse: 0.1741\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1610 - mse: 0.1610\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1496 - mse: 0.1496\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1384 - mse: 0.1384\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1276 - mse: 0.1276\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1180 - mse: 0.1180\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1086 - mse: 0.1086\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0998 - mse: 0.0998\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0921 - mse: 0.0921\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0846 - mse: 0.0846\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0776 - mse: 0.0776\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0716 - mse: 0.0716\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0659 - mse: 0.0659\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0606 - mse: 0.0606\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0557 - mse: 0.0557\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0510 - mse: 0.0510\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0468 - mse: 0.0468\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0428 - mse: 0.0428\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0392 - mse: 0.0392\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0359 - mse: 0.0359\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0330 - mse: 0.0330\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0304 - mse: 0.0304\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0279 - mse: 0.0279\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0256 - mse: 0.0256\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0234 - mse: 0.0234\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0214 - mse: 0.0214\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0179 - mse: 0.0179\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0149 - mse: 0.0149\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0136 - mse: 0.0136\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0124 - mse: 0.0124\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c6a54a6040>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the learning rate \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(50,activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "]\n",
    "\n",
    ")\n",
    "model.compile(loss = tf.keras.losses.mse , optimizer = tf.keras.optimizers.Adam(lr=50.002),metrics=['mse'])\n",
    "model.fit(x,y,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7bea0db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[28.126482]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd09c3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32.52167]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([20.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5252e30",
   "metadata": {},
   "source": [
    "### evaluting  a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d84294",
   "metadata": {},
   "source": [
    "in practice a typical workflow you'll go through when buliding a neural networks is :\n",
    "\n",
    "build a model --> fit it ---> evaluate it ---> tweek a model ---> fit it ---> evaluate it ----> tweak a model ----> fit it ---->evaulate it ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748cef0",
   "metadata": {},
   "source": [
    "when it comes to evaluation there are 3 words you should memorize\n",
    "\n",
    "'visualize ,visualize , visualize'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7a11d",
   "metadata": {},
   "source": [
    "visualize\n",
    "\n",
    "** the data -- what data are we working with  , what it look like\n",
    "\n",
    "** the model itself  -- what does our model look like\n",
    "\n",
    "\n",
    "** the training a model -- how does a model perform while it learns\n",
    "\n",
    "\n",
    "** the prediction of the model -- how do the predictions of a model line up against the ground truth(the original labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9ed99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make  a big dataset\n",
    "\n",
    "x =tf.range(-100,100,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86148722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec88ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a labels to a dataset\n",
    "\n",
    "y = x+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dad481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "779abfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x23bb592c4f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b241f",
   "metadata": {},
   "source": [
    "### the 3 sets ...\n",
    "\n",
    "\n",
    "** training set -- the model learns from the data , which is typically 70-80% of the total data \n",
    "\n",
    "** validation set -- the model gets tuned on this data , which is typically 10-15% of the data avalilable \n",
    "\n",
    "\n",
    "** test set -- the model gets evaluated on this data to test what is has learned , this set is typically 10-15% of the data avaliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415a5b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the length of how many samples we have \n",
    "\n",
    "len(x)  # sample size is small so skip the validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d55ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "\n",
    "x_train = x[:40] # first 40 (80% of data)\n",
    "x_test = x[40:]# last 10 (20% of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d35121",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[:40]\n",
    "y_test =y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04de920c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train) , len(x_test) , len(y_train) , len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed8e9f",
   "metadata": {},
   "source": [
    "## visualizing the data \n",
    "\n",
    "now we've got our data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e693680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23bb7a44d00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "#plot training data in blue\n",
    "plt.scatter(x_train,y_train,color='blue',label='training data')\n",
    "\n",
    "# plot testing datain green\n",
    "plt.scatter(x_test,y_test,c='green',label='testing data ')\n",
    "#show a legend \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8fe18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model \n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "]\n",
    ")\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae , optimizer = tf.keras.optimizers.SGD() , metrics=['mae'])\n",
    "\n",
    "# model.fit(x_train,y_train,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7400acc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30952/1792117753.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# visualize the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3480\u001b[0m         \"\"\"\n\u001b[0;32m   3481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3482\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   3483\u001b[0m                 \u001b[1;34m\"This model has not yet been built. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3484\u001b[0m                 \u001b[1;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "# visualize the model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d34abe36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape # it is a scaler value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82a85c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] , y[0]\n",
    "\n",
    "# the shape is 1 because we are passing one number to predict one number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03306fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a69534b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "# lets create a model which builds automatically by defining the input shape on the first layer \n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create a model\n",
    "\n",
    "model =tf.keras.Sequential(\n",
    "\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(1,input_shape=[1])\n",
    "    \n",
    "]\n",
    ")\n",
    "#compile the model\n",
    "\n",
    "model.compile(loss =tf.keras.losses.mae , optimizer = tf.keras.optimizers.SGD(lr=1.45),metrics=['mae'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead58d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # dense will be same as fully connected "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab2f15",
   "metadata": {},
   "source": [
    "** total paramters -- total number of parameters in the model \n",
    "\n",
    "** trainable parameters --these are the parameters (patterns ) the model can update as it trains \n",
    "\n",
    "** non-trainable params -- these parameters aren't updated during training (this is typical when you bring in already learn patterns or parameters from other models during **transfer learning)\n",
    "\n",
    "\n",
    "**** resource ****\n",
    "for a more in-depth overview of the trainable parameters within a layer , check out MIT's introduction to deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33af7ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23bb91f93d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs = 100 , verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91c7b78f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b8b071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76.447685],\n",
       "       [ 81.37391 ],\n",
       "       [ 86.30013 ],\n",
       "       [ 91.22635 ],\n",
       "       [ 96.15257 ],\n",
       "       [101.07879 ],\n",
       "       [106.00501 ],\n",
       "       [110.93124 ],\n",
       "       [115.85745 ],\n",
       "       [120.783676]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2a3664b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19bd47",
   "metadata": {},
   "source": [
    "#### converts a  keras model to dot format and save to file \n",
    "    \n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plt_model(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c530848",
   "metadata": {},
   "source": [
    "## visualize our model predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348fa7e3",
   "metadata": {},
   "source": [
    "to visualize predictions its a good idea to plot them against the ground truth tables \n",
    "\n",
    "often you'll see this in the form of y_test verses y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "500ab012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean absoulte error \n",
    "\n",
    "mae = tf.keras.losses.mae(y_true = y_test , y_pred = tf.constant(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d14e0f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([13.331388, 11.050436, 10.      , 10.24527 , 11.661029, 14.247273,\n",
       "       18.005013, 22.931236, 27.857452, 32.783676], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56293158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 76.447685],\n",
       "       [ 81.37391 ],\n",
       "       [ 86.30013 ],\n",
       "       [ 91.22635 ],\n",
       "       [ 96.15257 ],\n",
       "       [101.07879 ],\n",
       "       [106.00501 ],\n",
       "       [110.93124 ],\n",
       "       [115.85745 ],\n",
       "       [120.783676]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc6cc799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4167af3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 76.447685,  81.37391 ,  86.30013 ,  91.22635 ,  96.15257 ,\n",
       "       101.07879 , 106.00501 , 110.93124 , 115.85745 , 120.783676],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "865e1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean absoulte error\n",
    "\n",
    "mae = tf.metrics.mean_absolute_error(y_true = y_test , y_pred = tf.squeeze(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1432a6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=10.615682>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "547e6255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 76.447685],\n",
       "       [ 81.37391 ],\n",
       "       [ 86.30013 ],\n",
       "       [ 91.22635 ],\n",
       "       [ 96.15257 ],\n",
       "       [101.07879 ],\n",
       "       [106.00501 ],\n",
       "       [110.93124 ],\n",
       "       [115.85745 ],\n",
       "       [120.783676]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make some preditions \n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7fb2a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83b06311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a plotting function\n",
    "\n",
    "def plot_predictions(train_data=x_train , train_lables = y_train ,test_data = x_test ,test_labels = y_test ,predictions = y_pred):\n",
    "    '''plots training data , test data and compare predictions '''\n",
    "    plt.figure(figsize=(10,7))\n",
    "    # plot the training data\n",
    "    plt.scatter(train_data , train_lables , c='b' , label='training_data')\n",
    "    #plot the testing data\n",
    "    plt.scatter(test_data , test_labels , c='green',label ='testing_data ')\n",
    "    #plot model predictions\n",
    "    plt.scatter(test_data , predictions , c='red',label='predictions')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba9ddb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16d9f8",
   "metadata": {},
   "source": [
    "### evaluating our models predictions with regression evaluate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903659b",
   "metadata": {},
   "source": [
    "depending on the problem we are working on ,there will be different evaluation metrics to evaluate your model performance \n",
    "\n",
    "since working on regression problem there are 2 techniques\n",
    "\n",
    "1.MAE -- mean absolute error , 'on average , how wrong is each of my models predictions '\n",
    "\n",
    "2.MSE -- mean sqaure error , 'squaring the average errors '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6790c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 393ms/step - loss: 10.6157 - mae: 10.6157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.615681648254395, 10.615681648254395]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on test \n",
    "model.evaluate(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a14fb621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=119.77024>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 calculate the mean square error \n",
    "\n",
    "tf.keras.losses.mean_squared_error(y_true= y_test , y_pred = tf.squeeze(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0562abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some funtions to reuse mae , mse\n",
    "\n",
    "def mae(y_true , y_pred):\n",
    "    return tf.keras.losses.mean_absolute_error(y_true=y_true , y_pred = tf.squeeze(y_pred))\n",
    "def mse(y_true , y_pred):\n",
    "    return tf.keras.losses.mean_squared_error(y_true=y_true , y_pred = tf.squeeze(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336ffea",
   "metadata": {},
   "source": [
    "### running experiments to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e62e9a",
   "metadata": {},
   "source": [
    "1..get more data -- get more examples for your model to train\n",
    "\n",
    "2. make your model larger (using a more complex model) -- this might come in the form of more layers or more hidden layers in each layer\n",
    "\n",
    "3. train for longer -- give ur model more of a chance to find patterns in the data \n",
    "\n",
    "\n",
    "lets do 3 modelling experiments --\n",
    "\n",
    "1. model_1 -- same  as the original model , 1 layer , trained for 100 epochs \n",
    "\n",
    "2. model_2 -- 2 layers , trained for 100 epochs \n",
    "\n",
    "3. model_3 -- 2 layers , trained for 500 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "767dca82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train , y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b1b286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 18ms/step - loss: 60.5234 - mae: 60.5234\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 25.7561 - mae: 25.7561\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.6988 - mae: 10.6988\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.2811 - mae: 13.2811\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.7782 - mae: 7.7782\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.6195 - mae: 10.6195\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.5738 - mae: 9.5738\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 9.0288 - mae: 9.0288\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.8524 - mae: 17.8524\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.6244 - mae: 9.6244\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.2162 - mae: 8.2162\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.2910 - mae: 10.2910\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.0428 - mae: 12.0428\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.9535 - mae: 13.9535\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.3456 - mae: 11.3456\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.5727 - mae: 8.5727\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.6979 - mae: 13.6979\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.5384 - mae: 11.5384\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.8491 - mae: 17.8491\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 14.9843 - mae: 14.9843\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.8645 - mae: 10.8645\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.6169 - mae: 8.6169\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.7147 - mae: 9.7147\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.9773 - mae: 10.9773\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.1767 - mae: 9.1767\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.2156 - mae: 13.2156\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.6844 - mae: 10.6844\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 12.9091 - mae: 12.9091\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.5239 - mae: 9.5239\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.4385 - mae: 16.4385\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.5632 - mae: 23.5632\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6186 - mae: 7.6186\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.3144 - mae: 9.3144\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.6779 - mae: 13.6779\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.1735 - mae: 11.1735\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.4008 - mae: 13.4008\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.4587 - mae: 9.4587\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 10.1097 - mae: 10.1097\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 8.9857 - mae: 8.9857\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.6145 - mae: 9.6145\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.5755 - mae: 10.5755\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6296 - mae: 10.6296\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.2195 - mae: 7.2195\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.0267 - mae: 8.0267\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.8301 - mae: 9.8301\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.9102 - mae: 8.9102\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.5740 - mae: 7.5740\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.5363 - mae: 8.5363\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.0423 - mae: 10.0423\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.9819 - mae: 8.9819\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.7198 - mae: 10.7198\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.2627 - mae: 15.2627\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.2935 - mae: 14.2935\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 21.5385 - mae: 21.5385\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 16.0603 - mae: 16.0603\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 10.2453 - mae: 10.2453\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.8065 - mae: 9.8065\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.0886 - mae: 9.0886\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.2918 - mae: 8.2918\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.3844 - mae: 9.3844\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.2159 - mae: 11.2159\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.0319 - mae: 12.0319\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.2804 - mae: 7.2804\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.4756 - mae: 12.4756\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.5518 - mae: 10.5518\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 15.5637 - mae: 15.5637\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.9808 - mae: 9.9808\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.7134 - mae: 8.7134\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.4401 - mae: 13.4401\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4771 - mae: 7.4771\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.2786 - mae: 12.2786\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.5110 - mae: 8.5110\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.8768 - mae: 6.8768\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.1537 - mae: 11.1537\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.3756 - mae: 9.3756\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.8373 - mae: 10.8373\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.7048 - mae: 14.7048\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.1673 - mae: 11.1673\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.7261 - mae: 14.7261\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.9305 - mae: 8.9305\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.7690 - mae: 10.7690\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.4127 - mae: 8.4127\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.2275 - mae: 9.2275\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 8.9515 - mae: 8.9515\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.1864 - mae: 13.1864\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.7247 - mae: 13.7247\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.2095 - mae: 13.2095\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.5374 - mae: 11.5374\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.8203 - mae: 7.8203\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.9525 - mae: 10.9525\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.7622 - mae: 6.7622\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.1453 - mae: 10.1453\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.6140 - mae: 7.6140\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.2464 - mae: 9.2464\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.8305 - mae: 10.8305\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.3168 - mae: 10.3168\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.6837 - mae: 7.6837\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.6206 - mae: 8.6206\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.3984 - mae: 9.3984\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.8465 - mae: 8.8465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23bb930f220>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_1 = tf.keras.Sequential(\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(1 , input_shape=[1])\n",
    "]\n",
    "\n",
    "\n",
    ")\n",
    "model_1.compile(loss =tf.keras.losses.mae , optimizer = tf.keras.optimizers.SGD() , metrics = ['mae'])\n",
    "model_1.fit(x_train , y_train ,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8b9d2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    }
   ],
   "source": [
    "# make and plot predictions of model_1\n",
    "\n",
    "y_pred1 = model_1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecc0aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 74.56932 ],\n",
       "       [ 79.45499 ],\n",
       "       [ 84.34065 ],\n",
       "       [ 89.22631 ],\n",
       "       [ 94.11198 ],\n",
       "       [ 98.997635],\n",
       "       [103.8833  ],\n",
       "       [108.76897 ],\n",
       "       [113.654625],\n",
       "       [118.54029 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5040e91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions = y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59487ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b082941d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=8.554807>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=79.656006>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate model_1  evaluation metrics\n",
    "\n",
    "mae_1 =mae(y_test ,y_pred1)\n",
    "\n",
    "mse_1 = mse(y_test , y_pred1)\n",
    "\n",
    "mae_1 , mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3a5b6",
   "metadata": {},
   "source": [
    "## model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "490e4112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 65.3564 - mse: 6382.7725\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.2133 - mse: 581.3535\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.1556 - mse: 532.9695\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.8455 - mse: 246.9064\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 15.3022 - mse: 299.3038\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.1469 - mse: 181.9157\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.4371 - mse: 158.6758\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 11.1819 - mse: 172.5601\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 41.5078 - mse: 2741.0400\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.7669 - mse: 1168.9590\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.4119 - mse: 118.9468\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 26.2310 - mse: 952.1113\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.5202 - mse: 283.2705\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 30.0526 - mse: 1444.7354\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.8659 - mse: 552.7478\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.8856 - mse: 126.0028\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.7521 - mse: 416.7721\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 14.2219 - mse: 319.5750\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.0656 - mse: 309.0251\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2614 - mse: 147.0525\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.3919 - mse: 429.2929\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.6281 - mse: 336.9085\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.2381 - mse: 118.8668\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.2262 - mse: 406.1349\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.9138 - mse: 332.4544\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.8662 - mse: 646.2562\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.1088 - mse: 1065.0392\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.5882 - mse: 547.1886\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2530 - mse: 97.1862\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 29.2075 - mse: 1527.7888\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 52.9148 - mse: 5009.0127\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.9814 - mse: 210.3742\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.6031 - mse: 335.7342\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.6741 - mse: 213.1351\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.2354 - mse: 92.6572\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.6030 - mse: 401.0649\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.0572 - mse: 192.4665\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 18.1832 - mse: 434.9203\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 19.1197 - mse: 531.1779\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 20.4635 - mse: 611.8184\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.8821 - mse: 277.9081\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 12.2605 - mse: 185.0850\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 10.7257 - mse: 165.6861\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 22.9389 - mse: 823.7953\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.3724 - mse: 128.9124\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.7598 - mse: 179.9200\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.6652 - mse: 153.8170\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 17.2734 - mse: 404.7186\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.5558 - mse: 99.4421\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 13.7813 - mse: 257.9591\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 11.5864 - mse: 154.2098\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 30.4307 - mse: 1599.0282\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.3039 - mse: 300.0950\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.6512 - mse: 842.7907\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.5829 - mse: 912.5361\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3383 - mse: 171.7783\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.3560 - mse: 225.0798\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.9458 - mse: 109.4266\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.9091 - mse: 275.3257\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9885 - mse: 118.7773\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.9657 - mse: 307.8487\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.9220 - mse: 196.3712\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.2852 - mse: 134.7587\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.8778 - mse: 837.9032\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.4617 - mse: 130.0888\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.9252 - mse: 643.9369\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.4394 - mse: 126.2268\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.1714 - mse: 302.3497\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.5103 - mse: 125.8916\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.5813 - mse: 200.7728\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.0113 - mse: 225.8553\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.3543 - mse: 531.5071\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.1270 - mse: 193.3060\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.4420 - mse: 717.5848\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.4581 - mse: 151.5400\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.2813 - mse: 182.9226\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.3196 - mse: 410.2166\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.0080 - mse: 92.0155\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.5680 - mse: 831.8185\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.2643 - mse: 1061.0480\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.4412 - mse: 160.9611\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.4413 - mse: 226.5871\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.1067 - mse: 380.7331\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.2559 - mse: 76.0865\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 37.1761 - mse: 2221.9358\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.1957 - mse: 645.7223\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.0198 - mse: 147.9917\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 25.0571 - mse: 893.4375\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.3530 - mse: 136.8899\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.3625 - mse: 432.5611\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.7935 - mse: 160.4848\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.0502 - mse: 499.9929\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.3118 - mse: 102.5733\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.5513 - mse: 178.0599\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.0848 - mse: 1032.2632\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.1791 - mse: 169.7182\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.7637 - mse: 428.9033\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.5882 - mse: 60.8183\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.6075 - mse: 229.5885\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.4269 - mse: 554.1395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23bba53c940>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_2 = tf.keras.Sequential(\n",
    "\n",
    "[\n",
    "    tf.keras.layers.Dense(10,input_shape=[1]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "]\n",
    "\n",
    ")\n",
    "\n",
    "model_2.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.SGD() , metrics = ['mse'])\n",
    "\n",
    "model_2.fit(x_train,y_train ,epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9dd1d08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 212ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model_2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "032c706e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 78.22172 ],\n",
       "       [ 83.31875 ],\n",
       "       [ 88.415794],\n",
       "       [ 93.51284 ],\n",
       "       [ 98.60988 ],\n",
       "       [103.706924],\n",
       "       [108.80396 ],\n",
       "       [113.90101 ],\n",
       "       [118.998055],\n",
       "       [124.09509 ]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17f33c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions=y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d59bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_2 = mae(y_test , y_pred2)\n",
    "mse_2 = mse(y_test , y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73378bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=13.1584015>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=183.07243>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_2,mse_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0973e5a1",
   "metadata": {},
   "source": [
    "### build model 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "669b0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 16.5397 - mse: 400.1829\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.9261 - mse: 64.7808\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 21.6665 - mse: 676.6884\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 22.6498 - mse: 746.0246\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.7942 - mse: 174.1944\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.4654 - mse: 101.0752\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.5012 - mse: 145.1626\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.8986 - mse: 242.9487\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 26.7549 - mse: 1010.7064\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 17.1213 - mse: 416.2694\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 12.2062 - mse: 263.1216\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 21.8677 - mse: 694.2056\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 24.6579 - mse: 881.9686\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.3451 - mse: 906.7479\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.9155 - mse: 314.5760\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.4069 - mse: 109.5632\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 16.4896 - mse: 370.5307\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.8763 - mse: 180.0807\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 16.9578 - mse: 466.0516\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.7131 - mse: 131.9869\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 16.5770 - mse: 394.0170\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.9105 - mse: 314.2411\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.7479 - mse: 61.4034\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.3764 - mse: 166.7450\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.1831 - mse: 535.7354\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.1092 - mse: 239.7978\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.7868 - mse: 199.9397\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 22.5456 - mse: 795.7208\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.0848 - mse: 86.9588\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 27.9676 - mse: 1347.0400\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 50.3885 - mse: 4505.5654\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.7355 - mse: 171.2022\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.6359 - mse: 141.0081\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 23.0795 - mse: 798.3563\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 12.3452 - mse: 250.5793\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.5036 - mse: 603.6741\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.6728 - mse: 212.7423\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.3052 - mse: 392.8612\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.2842 - mse: 476.6467\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.8584 - mse: 532.0042\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.6707 - mse: 461.7873\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.2502 - mse: 96.9262\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.8613 - mse: 90.4930\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 33.8941 - mse: 1894.0648\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.7218 - mse: 268.9543\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4746 - mse: 66.8700\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.8144 - mse: 193.7319\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.5229 - mse: 332.7033\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.1115 - mse: 232.0090\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.6930 - mse: 242.5859\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.5624 - mse: 303.3799\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.1425 - mse: 497.6464\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.2260 - mse: 773.4025\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 25.4781 - mse: 974.0288\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 24.8191 - mse: 923.0928\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.7498 - mse: 145.9694\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.2000 - mse: 203.7775\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.7151 - mse: 83.1303\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.3899 - mse: 141.8053\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.0371 - mse: 136.0618\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.7102 - mse: 552.6268\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.3417 - mse: 97.4451\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.0217 - mse: 174.7664\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.7224 - mse: 323.9608\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.7391 - mse: 88.5067\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.4499 - mse: 822.5253\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.1204 - mse: 101.5088\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.2736 - mse: 317.3385\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.5375 - mse: 87.9759\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6168 - mse: 154.2800\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.9457 - mse: 329.3443\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.7580 - mse: 118.3276\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.6675 - mse: 300.2898\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 22.3597 - mse: 769.7256\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.2641 - mse: 86.3295\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.7216 - mse: 529.8635\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 32.1235 - mse: 1733.5580\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.6286 - mse: 247.8748\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.5451 - mse: 403.4276\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.5378 - mse: 564.7750\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9777 - mse: 77.6928\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.8495 - mse: 260.2567\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.3330 - mse: 401.3130\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4058 - mse: 99.5554\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 25.5024 - mse: 914.1127\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.6859 - mse: 373.4648\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.5583 - mse: 125.5482\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.9643 - mse: 813.4461\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.3903 - mse: 57.2995\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 29.7449 - mse: 1336.0051\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 12.0073 - mse: 195.6629\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 21.1943 - mse: 620.8517\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.7545 - mse: 70.1818\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.0921 - mse: 324.8849\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3315 - mse: 273.9014\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.7082 - mse: 276.9966\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.8138 - mse: 284.6938\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.5538 - mse: 343.1691\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.2928 - mse: 192.6942\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 22.5944 - mse: 721.4786\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.7695 - mse: 855.5724\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.5310 - mse: 135.8538\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.1171 - mse: 78.1544\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 24.7384 - mse: 911.6012\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.8583 - mse: 187.1650\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.1122 - mse: 89.0228\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 22.4127 - mse: 748.8678\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0982 - mse: 74.4898\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.6962 - mse: 276.1085\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.7228 - mse: 238.1739\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.7605 - mse: 474.8776\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 6.4018 - mse: 58.9268\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.5757 - mse: 611.5745\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 28.6065 - mse: 1303.6853\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.2549 - mse: 341.5320\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.3056 - mse: 143.7056\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.9646 - mse: 281.8582\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.3615 - mse: 154.2516\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.5526 - mse: 263.5515\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 31.3874 - mse: 1355.6223\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.8334 - mse: 256.9077\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 27.6085 - mse: 1021.4935\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.5445 - mse: 371.9892\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.0971 - mse: 110.2734\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.4446 - mse: 280.2803\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.8780 - mse: 73.6020\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.6670 - mse: 429.3136\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0221 - mse: 105.8269\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.1779 - mse: 461.8918\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.9040 - mse: 98.2951\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.2056 - mse: 673.9752\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.1066 - mse: 81.5292\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.0777 - mse: 121.5928\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.5081 - mse: 561.2843\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8979 - mse: 130.7685\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.9623 - mse: 412.2877\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.5880 - mse: 521.5945\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.3251 - mse: 46.7351\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.1237 - mse: 324.0043\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.8341 - mse: 223.9990\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.5363 - mse: 560.3130\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 33.9678 - mse: 1963.7629\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 22.4554 - mse: 707.9519\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.5028 - mse: 233.4361\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 24.5733 - mse: 828.0933\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.2967 - mse: 197.4392\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.1262 - mse: 322.9513\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.5824 - mse: 493.9670\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.8827 - mse: 32.8200\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.6557 - mse: 301.3417\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.4225 - mse: 697.0512\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.6381 - mse: 816.2909\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 18.4794 - mse: 456.5996\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.6448 - mse: 259.9445\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.5967 - mse: 369.2321\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.1451 - mse: 445.2162\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 32.2279 - mse: 1658.7836\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.0593 - mse: 119.1736\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.7424 - mse: 82.2033\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.6370 - mse: 673.3781\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.3224 - mse: 168.6557\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 20.3688 - mse: 592.7393\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.9789 - mse: 466.6483\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.0937 - mse: 167.2385\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1564 - mse: 229.6652\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 21.5938 - mse: 683.4201\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.3464 - mse: 1046.9529\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.0469 - mse: 141.7908\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.4887 - mse: 699.5137\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.4364 - mse: 245.7932\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.2330 - mse: 563.4529\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 34.2199 - mse: 1872.7172\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.6514 - mse: 595.0784\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.5759 - mse: 204.7977\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.9414 - mse: 1057.0686\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.3518 - mse: 152.2654\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1052 - mse: 254.5502\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.3903 - mse: 509.0847\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1429 - mse: 138.9734\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.3702 - mse: 77.7586\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.7391 - mse: 557.0973\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.7841 - mse: 168.7814\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.2517 - mse: 97.6657\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 39.9021 - mse: 2477.7087\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.5820 - mse: 75.4770\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.0094 - mse: 624.4303\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9978 - mse: 229.1421\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.4894 - mse: 879.3859\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.6847 - mse: 224.4704\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.6209 - mse: 80.5666\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.1635 - mse: 253.3491\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0677 - mse: 256.3900\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.0132 - mse: 1099.0779\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8809 - mse: 66.3145\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.0237 - mse: 89.4821\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.5888 - mse: 610.4789\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.7703 - mse: 212.9348\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.0089 - mse: 752.8681\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.8713 - mse: 914.8719\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.5938 - mse: 517.1962\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2290 - mse: 305.9728\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.5610 - mse: 606.7650\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.4929 - mse: 937.9131\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.3763 - mse: 616.9952\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.0772 - mse: 111.7937\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.7120 - mse: 252.6664\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0474 - mse: 123.7427\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 22.7113 - mse: 728.6383\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.3731 - mse: 399.3231\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.1506 - mse: 478.4882\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.5447 - mse: 133.6166\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.5698 - mse: 465.6381\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 14.7673 - mse: 301.0735\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.4654 - mse: 290.7578\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.8784 - mse: 779.8186\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.3140 - mse: 320.3028\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.0602 - mse: 74.0170\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.5709 - mse: 207.5512\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.7085 - mse: 50.3302\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1352 - mse: 40.7013\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 38.4317 - mse: 2536.9851\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 37.9070 - mse: 2322.7898\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.2925 - mse: 82.2189\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.9842 - mse: 353.2300\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.0362 - mse: 383.2812\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8923 - mse: 379.9476\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 16.2004 - mse: 376.4086\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.1129 - mse: 289.3018\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.8678 - mse: 643.6203\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.0084 - mse: 315.3511\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.6548 - mse: 31.0201\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.4936 - mse: 262.1649\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 25.6811 - mse: 928.2015\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.0333 - mse: 323.1934\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3095 - mse: 82.3559\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 20.5064 - mse: 628.2457\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 13.9924 - mse: 289.0045\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.1934 - mse: 259.9043\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.8746 - mse: 601.1776\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.6647 - mse: 736.0732\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.1454 - mse: 115.9037\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.6239 - mse: 423.0486\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.8283 - mse: 123.8494\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.6762 - mse: 225.1337\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.0679 - mse: 311.5894\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.7718 - mse: 561.2294\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 35.5314 - mse: 1946.3015\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.0865 - mse: 43.3531\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.9035 - mse: 317.0888\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.8037 - mse: 834.9958\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.4877 - mse: 290.1382\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.2775 - mse: 591.6366\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.2040 - mse: 97.9314\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.3432 - mse: 307.3627\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.9359 - mse: 212.2121\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.5573 - mse: 118.9474\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.5319 - mse: 288.4351\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4935 - mse: 125.0293\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 24.5821 - mse: 825.5570\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 25.4716 - mse: 952.5613\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.0056 - mse: 124.0008\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.2847 - mse: 111.1908\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.0861 - mse: 92.5511\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.4103 - mse: 424.0593\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.1051 - mse: 212.5841\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.4835 - mse: 261.0893\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.7768 - mse: 227.8674\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.5821 - mse: 667.8288\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 33.3423 - mse: 1660.6393\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.8965 - mse: 163.1989\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.8027 - mse: 284.3420\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.9896 - mse: 1011.9265\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.3778 - mse: 146.2595\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.8029 - mse: 319.6504\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 28.3272 - mse: 1156.2251\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.2376 - mse: 104.9447\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.6222 - mse: 968.7373\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.7521 - mse: 222.7102\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 15.7272 - mse: 369.4685\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 20.3963 - mse: 641.5587\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.7259 - mse: 581.7540\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.2023 - mse: 82.6804\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.3852 - mse: 79.8958\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.7502 - mse: 992.2039\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.6797 - mse: 295.6035\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.3657 - mse: 254.4302\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 20.0734 - mse: 616.2154\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 29.6896 - mse: 1337.5029\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.6250 - mse: 186.3288\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.2067 - mse: 354.4867\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4122 - mse: 401.3457\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.4184 - mse: 413.5748\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.9834 - mse: 551.5721\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 32.9945 - mse: 1753.3969\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.3722 - mse: 141.6130\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8600 - mse: 64.5014\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.1652 - mse: 79.5101\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.1123 - mse: 974.2882\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.5170 - mse: 291.6972\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.7229 - mse: 41.2333\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 21.7576 - mse: 659.4510\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.8973 - mse: 69.0556\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.0704 - mse: 528.4491\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.7288 - mse: 233.2132\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7260 - mse: 75.2997\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.4407 - mse: 825.8838\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.7856 - mse: 553.9081\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.1407 - mse: 75.9784\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.6601 - mse: 238.6015\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.3529 - mse: 228.4984\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.6826 - mse: 264.3017\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 28.6509 - mse: 1143.6708\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.3022 - mse: 173.2696\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.5763 - mse: 255.5361\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.5522 - mse: 875.7643\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6366 - mse: 413.4951\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 19.8537 - mse: 542.9366\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.9708 - mse: 65.8566\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.3987 - mse: 452.1306\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.4493 - mse: 128.2581\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.7772 - mse: 196.6766\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.5263 - mse: 250.2517\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.9874 - mse: 508.3141\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.9923 - mse: 346.9600\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.8441 - mse: 512.2995\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.3658 - mse: 813.3837\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.8444 - mse: 165.6952\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.0022 - mse: 244.1223\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.4263 - mse: 476.5890\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.1021 - mse: 82.2174\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.5449 - mse: 632.0019\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.2746 - mse: 183.9505\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.9675 - mse: 268.9567\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3666 - mse: 219.7245\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2405 - mse: 260.1445\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.5992 - mse: 1455.4973\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3928 - mse: 201.7925\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.8283 - mse: 584.6367\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 34.5806 - mse: 1789.1975\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.8402 - mse: 171.2630\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.3665 - mse: 214.6744\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.1143 - mse: 375.4811\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.9309 - mse: 190.2634\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7921 - mse: 270.4999\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.3528 - mse: 1303.4553\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.9224 - mse: 225.8548\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 25.6423 - mse: 928.2137\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.0628 - mse: 268.3115\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.5423 - mse: 257.0312\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.3738 - mse: 336.4071\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 32.9791 - mse: 1529.1575\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.0415 - mse: 277.5269\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.6353 - mse: 487.7292\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2788 - mse: 233.8736\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 26.7330 - mse: 1027.8019\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 10.6908 - mse: 209.7369\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9119 - mse: 222.9875\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.8081 - mse: 300.6342\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.7398 - mse: 290.2837\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 22.4401 - mse: 746.8030\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.3055 - mse: 492.5748\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.0932 - mse: 71.5208\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 23.9586 - mse: 832.0737\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 29.6086 - mse: 1271.5881\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.6998 - mse: 98.6941\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.4672 - mse: 40.7561\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 38.3664 - mse: 2251.6399\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4582 - mse: 97.7898\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.9605 - mse: 230.6293\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.3577 - mse: 266.7270\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.3323 - mse: 563.3588\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.5578 - mse: 302.7023\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.9268 - mse: 914.4099\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.5002 - mse: 294.9987\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.1697 - mse: 243.7526\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.8918 - mse: 321.4704\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.9234 - mse: 326.5730\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.6649 - mse: 491.6482\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 36.1117 - mse: 1955.5502\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 32.3304 - mse: 1550.6429\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0929 - mse: 83.6954\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1745 - mse: 251.4340\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.7637 - mse: 125.5996\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.9657 - mse: 59.2563\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5197 - mse: 286.6347\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.9790 - mse: 568.8727\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.6298 - mse: 1029.4319\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3100 - mse: 193.6583\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.1798 - mse: 258.3506\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.5705 - mse: 416.0536\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 16.2986 - mse: 378.1357\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.7279 - mse: 345.1788\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.7207 - mse: 561.8285\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.0811 - mse: 1032.5076\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.8457 - mse: 618.6774\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.1789 - mse: 163.7860\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.6305 - mse: 174.6762\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 20.3563 - mse: 642.2267\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.4586 - mse: 802.9025\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.2200 - mse: 262.9162\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.9991 - mse: 292.0029\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.7895 - mse: 876.9259\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.4113 - mse: 355.8846\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.0369 - mse: 145.1549\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4503 - mse: 197.9935\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.3761 - mse: 67.9607\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.6160 - mse: 276.0667\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.9341 - mse: 33.7029\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 29.1175 - mse: 1285.2886\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6743 - mse: 263.8724\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.3202 - mse: 271.9419\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.9573 - mse: 682.9289\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 14.2099 - mse: 304.3585\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.7915 - mse: 228.3418\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.1357 - mse: 285.3109\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.5724 - mse: 850.6545\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.8405 - mse: 519.4831\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.4764 - mse: 233.9513\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.3261 - mse: 340.0820\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.8495 - mse: 798.9179\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.6033 - mse: 549.5165\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7856 - mse: 11.2553\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 23.0193 - mse: 768.2360\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.0511 - mse: 641.7163\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.4588 - mse: 224.2237\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.9502 - mse: 150.5322\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.3287 - mse: 483.3342\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.9380 - mse: 263.3062\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.5914 - mse: 1025.0670\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.7459 - mse: 392.3587\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9441 - mse: 182.4880\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.1758 - mse: 270.0832\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.5873 - mse: 305.8314\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 30.4841 - mse: 1306.7891\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.2570 - mse: 364.3453\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 28.1099 - mse: 1161.9287\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.8557 - mse: 11.0110\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.0941 - mse: 232.9361\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 34.4956 - mse: 1649.0127\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.0319 - mse: 348.5896\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.7371 - mse: 562.4120\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 25.8408 - mse: 963.5609\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4231 - mse: 192.8271\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.3068 - mse: 61.8282\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.1375 - mse: 231.2514\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.9311 - mse: 326.3781\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 21.7918 - mse: 737.2686\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.8537 - mse: 183.1684\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.4451 - mse: 261.2589\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.4387 - mse: 339.4309\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 17.6653 - mse: 496.7132\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 43.7471 - mse: 3317.3782\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 25.0054 - mse: 888.5677\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.1007 - mse: 643.8732\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.8352 - mse: 59.1093\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.7349 - mse: 168.9388\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.8999 - mse: 299.8793\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.9835 - mse: 307.3568\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 27.7553 - mse: 1100.0052\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.1039 - mse: 197.6070\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.1983 - mse: 263.7962\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.7439 - mse: 263.7131\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 30.1301 - mse: 1268.6836\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.5240 - mse: 222.2798\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 20.4286 - mse: 647.4064\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.7795 - mse: 1131.4055\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 16.7501 - mse: 407.2650\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.5639 - mse: 317.1991\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 26.7741 - mse: 1011.9133\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 13.9414 - mse: 318.0789\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 10.6996 - mse: 213.5144\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.8021 - mse: 365.3343\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 16.1163 - mse: 437.4564\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 48.3948 - mse: 3779.3823\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.0736 - mse: 691.7377\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.6867 - mse: 247.4783\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.4309 - mse: 1137.2698\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 6.4407 - mse: 73.8355\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.3626 - mse: 57.8977\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.9415 - mse: 519.1168\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.1839 - mse: 305.9477\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.1309 - mse: 547.8823\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.4980 - mse: 593.6010\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.5368 - mse: 482.8205\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.2206 - mse: 238.5212\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.4815 - mse: 528.1848\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.6700 - mse: 69.7435\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 29.8089 - mse: 1297.5986\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.6064 - mse: 239.2284\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 13.0320 - mse: 246.9443\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.3297 - mse: 883.2247\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 18.7832 - mse: 498.3347\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4032 - mse: 8.3509\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 11.5036 - mse: 214.8086\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 14.1435 - mse: 270.7180\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 13.0230 - mse: 244.0488\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.1586 - mse: 546.5602\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 22.3085 - mse: 721.7087\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.3614 - mse: 113.5695\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.5782 - mse: 305.3594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23bbb01dfa0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_3 = tf.keras.Sequential(\n",
    "\n",
    "\n",
    "[\n",
    "    \n",
    "    tf.keras.layers.Dense(100,input_shape=[1]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "])\n",
    "\n",
    "model_2.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.SGD() , metrics = ['mse'])\n",
    "\n",
    "model_2.fit(x_train , y_train ,epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3698adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 211ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = model_3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2fd1641d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6231537],\n",
       "       [-1.7313619],\n",
       "       [-1.8395729],\n",
       "       [-1.9477844],\n",
       "       [-2.055997 ],\n",
       "       [-2.1642027],\n",
       "       [-2.272416 ],\n",
       "       [-2.3806229],\n",
       "       [-2.4888363],\n",
       "       [-2.5970426]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21f61cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(predictions = y_pred3)\n",
    "\n",
    "\n",
    "# here the model is trained for long time this is called overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "63e311e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=90.1101>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8259.068>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_3 = mae(y_test , y_pred3)\n",
    "mse_3 = mse(y_test , y_pred3)\n",
    "mae_3 , mse_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e1f46",
   "metadata": {},
   "source": [
    "### comparing the results of our experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52231a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>tf.Tensor(8.554807, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(79.656006, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>tf.Tensor(13.1584015, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(183.07243, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>tf.Tensor(90.1101, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(8259.068, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                             mae  \\\n",
       "0  model_1     tf.Tensor(8.554807, shape=(), dtype=float32)   \n",
       "1  model_2   tf.Tensor(13.1584015, shape=(), dtype=float32)   \n",
       "2   model_3     tf.Tensor(90.1101, shape=(), dtype=float32)   \n",
       "\n",
       "                                             mse  \n",
       "0  tf.Tensor(79.656006, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(183.07243, shape=(), dtype=float32)  \n",
       "2   tf.Tensor(8259.068, shape=(), dtype=float32)  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets compare our model results using pandas DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "model_results = [['model_1 ' , mae_1 ,mse_1] , ['model_2 ', mae_2,mse_2] , ['model_3', mae_3 , mse_3]]\n",
    "\n",
    "all_results =pd.DataFrame(model_results , columns = ['model' , 'mae' , 'mse'])\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65f78ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>8.554807</td>\n",
       "      <td>79.656006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>13.158401</td>\n",
       "      <td>183.072433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>90.110100</td>\n",
       "      <td>8259.068359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model        mae          mse\n",
       "0  model_1    8.554807    79.656006\n",
       "1  model_2   13.158401   183.072433\n",
       "2   model_3  90.110100  8259.068359"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_results = [['model_1 ' , mae_1.numpy() ,mse_1.numpy()] , ['model_2 ', mae_2.numpy(),mse_2.numpy()] , ['model_3', mae_3.numpy() , mse_3.numpy()]]\n",
    "\n",
    "all_results =pd.DataFrame(model_results , columns = ['model' , 'mae' , 'mse'])\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8d84b151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc2ad3",
   "metadata": {},
   "source": [
    "### tracking your experiments \n",
    "\n",
    "one really good habit in machine learning modelling is to track the results of your experiments ... \n",
    "\n",
    "and when doing so , it can be tedious if you're running lots of experiments \n",
    "\n",
    "luckily there are tools to help us \n",
    "\n",
    "\n",
    "* TensorBoard -- a component of the tensorflow library to help track modelling experiments \n",
    "\n",
    "* weights and biases -- a tool for tracking all kinds of machine learning experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9273c8a",
   "metadata": {},
   "source": [
    "### saving our models \n",
    "\n",
    "saving our models allows us to use them outside wherever such as web application or mobile\n",
    "\n",
    "there are 2 main formats to save a model\n",
    "\n",
    "* the SavedModel format\n",
    "\n",
    "* the HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3453cf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_SavedModel_format\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_SavedModel_format\\assets\n"
     ]
    }
   ],
   "source": [
    "# save the model \n",
    "\n",
    "model_1.save('best_model_SavedModel_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3416a",
   "metadata": {},
   "source": [
    "### HDF5 format  (hierarchical data file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d42d7dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Public\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_1.save('best_model_HDF5_format.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b57cae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('my_model.keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d694e",
   "metadata": {},
   "source": [
    "# loading in a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "593ed944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load in the savedmodel format\n",
    "\n",
    "loaded_SavedModel_format = tf.keras.models.load_model('best_model_SavedModel_format')\n",
    "loaded_SavedModel_format.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f45615ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 179ms/step\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023BBC1E4CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023BBC1E4CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 202ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare model_2 predictions with SavedModel format model predictions\n",
    "\n",
    "model_1_preds = model_1.predict(x_test)\n",
    "\n",
    "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(x_test)\n",
    "\n",
    "model_1_preds == loaded_SavedModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e5f015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load in a model using the .h5 format\n",
    "loaded_h5_format = tf.keras.models.load_model('best_model_HDF5_format.h5')\n",
    "loaded_h5_format.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6bb2d429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 155ms/step\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023BBC27F1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023BBC27F1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 203ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare model_2 predictions with .h5 format model predictions\n",
    "\n",
    "\n",
    "model_1_preds1 = model_1.predict(x_test)\n",
    "\n",
    "loaded_h5_format_preds = loaded_h5_format.predict(x_test)\n",
    "\n",
    "model_1_preds1 == loaded_SavedModel_format_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853c25e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e06e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
